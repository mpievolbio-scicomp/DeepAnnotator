{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start codon classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load general_lstm_start_classification.py\n",
    "import os, sys\n",
    "import random, h5py\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Program\n",
    "alphabet = \"NACGT\"\n",
    "vocab_size = 5\n",
    "batch_size = 10000\t\t#Original 10000\n",
    "embedding_size = 4\t\t#Original 8\n",
    "time_steps = 101\n",
    "category = 2\n",
    "max_data_size = 15200000\t#Original 1.5 Mil\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "CODING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Input File\n",
    "def read_input_file(file_path, label=-1):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    file_read = open(file_path, \"r\")\n",
    "    for line in file_read:\n",
    "        data = [int(i) for i in line.strip()]\n",
    "        x_data.append(data)\n",
    "        y_data.append(label)\n",
    "        #print(x_data[-1], y_data[-1])\n",
    "        if len(x_data) == max_data_size:\n",
    "            break\n",
    "    file_read.close()\n",
    "    print(\"Sequences Read: \", len(x_data))\n",
    "    return np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "x_data_pos, y_data_pos = read_input_file(\"./gene_range_\"+sys.argv[1]+\"_codon.txt\", 1)\n",
    "x_data_nogene, y_data_nogene = read_input_file(\"./intragenic_\"+sys.argv[1]+\"_codon.txt\", 0)\n",
    "x_data_coding, y_data_coding = read_input_file(\"./coding_\"+sys.argv[1]+\"_codon.txt\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_data_pos.shape, x_data_nogene.shape, x_data_coding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I'm not sure what 'CODING' is supposed to do but it's something about\n",
    "structuring the data.\n",
    "\"\"\"\n",
    "\n",
    "if CODING == True:\n",
    "    x_data_neg = np.concatenate((x_data_nogene, x_data_coding), axis=0)\n",
    "    y_data_neg = np.concatenate((y_data_nogene, y_data_coding), axis=0)\n",
    "else:\n",
    "    x_data_neg = x_data_nogene\n",
    "    y_data_neg = y_data_nogene\n",
    "\n",
    "np.random.shuffle(x_data_pos)\n",
    "np.random.shuffle(x_data_neg)\n",
    "print(CODING, x_data_pos.shape, x_data_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Data Index\n",
    "train_index = int((len(x_data_pos) / batch_size) * 0.60 * batch_size)\n",
    "eval_index = train_index + int((len(x_data_pos) / batch_size) * 0.20 * batch_size)\n",
    "test_index = eval_index + int((len(x_data_pos) / batch_size) * 0.20 * batch_size)\n",
    "print(\"train, eval, test = \", (train_index, eval_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Negative Data\n",
    "x_train = x_data_neg[0:train_index]\n",
    "y_train = y_data_neg[0:train_index]\n",
    "\n",
    "x_eval = x_data_neg[train_index:eval_index]\n",
    "y_eval = y_data_neg[train_index:eval_index]\n",
    "\n",
    "x_test = x_data_neg[eval_index:test_index]\n",
    "y_test = y_data_neg[eval_index:test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Positive Data\n",
    "x_train = np.append(x_train, x_data_pos[0:train_index], axis=0)\n",
    "y_train = np.append(y_train, y_data_pos[0:train_index], axis=0)\n",
    "\n",
    "x_eval = np.append(x_eval, x_data_pos[train_index:eval_index], axis=0)\n",
    "y_eval = np.append(y_eval, y_data_pos[train_index:eval_index], axis=0)\n",
    "\n",
    "x_test = np.append(x_test, x_data_pos[eval_index:test_index], axis=0)\n",
    "y_test = np.append(y_test, y_data_pos[eval_index:test_index], axis=0)\n",
    "\n",
    "print(\"Sanity Check: \", np.sum(y_train), np.sum(y_eval), np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Iterator\n",
    "train_iter = mx.io.NDArrayIter(data=x_train, label=y_train, \\\n",
    "                               data_name='data', label_name='label', \\\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "print(train_iter.data)\n",
    "\n",
    "eval_iter = mx.io.NDArrayIter(data=x_eval, label=y_eval, \\\n",
    "                               data_name='data', label_name='label', \\\n",
    "                               batch_size=batch_size, shuffle=True)\n",
    "print(eval_iter.data)\n",
    "\n",
    "test_iter = mx.io.NDArrayIter(data=x_test, label=y_test, \\\n",
    "                               data_name='data', label_name='label', \\\n",
    "                               batch_size=batch_size, shuffle=False)\n",
    "print(test_iter.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "unroll_dim = time_steps #Length of sequence\n",
    "sequence_dim = 2*unroll_dim #Sum of two sequence length\n",
    "\n",
    "num_hidden = 128 #Output unit of lstm layer\n",
    "num_embed = embedding_size #Dimension of embeddings\n",
    "num_label = category #dense network output\n",
    "\n",
    "max_features = vocab_size #Number of events\n",
    "#multiply = 100 #Control the size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = mx.sym.Variable(name='data')\n",
    "session_src = mx.sym.slice_axis(data=session, axis=1, begin=0, end=unroll_dim, name='source')\n",
    "#session_tar = mx.sym.slice_axis(data=session, axis=1, begin=unroll_dim, end=sequence_dim, name='target')\n",
    "embed_weight = mx.sym.Variable(name='weight')\n",
    "label = mx.sym.Variable(name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shared Embedding Layer\n",
    "#Original Dropout 0.40\n",
    "embed_seq_src = mx.sym.Embedding(data=session_src, \\\n",
    "                                input_dim=max_features, \\\n",
    "                                output_dim=num_embed, \\\n",
    "                                weight=embed_weight, \\\n",
    "                                name='vocab_embed_src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shared LSTM Layer\n",
    "fused_lstm_src = mx.rnn.FusedRNNCell(num_hidden=num_hidden, \\\n",
    "                                mode='lstm', \\\n",
    "                                prefix='lstm_src_', \\\n",
    "                                forget_bias=True, \\\n",
    "\t\t\t\tbidirectional=True, \\\n",
    "                                dropout=0.20)\t#Original 0.50\n",
    "fused_lstm_src.reset()\n",
    "\n",
    "lstm_outputs_src, _ = fused_lstm_src.unroll(length=unroll_dim, \\\n",
    "                                inputs=embed_seq_src, \\\n",
    "                                merge_outputs=True, \\\n",
    "                                layout=\"NTC\")\n",
    "\n",
    "fused_lstm_tar = mx.rnn.FusedRNNCell(num_hidden=num_hidden, \\\n",
    "                                mode='lstm', \\\n",
    "                                prefix='lstm_tar_', \\\n",
    "                                #params = fused_lstm_src.params, \\\n",
    "                                forget_bias=True, \\\n",
    "\t\t\t\tbidirectional=True, \\\n",
    "                                dropout=0.20)\t#Original 0.50\n",
    "fused_lstm_tar.reset()\n",
    "\n",
    "lstm_outputs_tar, _ = fused_lstm_tar.unroll(length=unroll_dim, \\\n",
    "                                inputs=lstm_outputs_src, \\\n",
    "                                merge_outputs=False, \\\n",
    "                                layout=\"NTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Layer\n",
    "out_lstm1 = mx.sym.Reshape(data=lstm_outputs_tar[-1], shape=(int(batch_size/8), -1), name=\"reshape_lstm_src\")\n",
    "#out_lstm2 = mx.sym.Reshape(data=lstm_outputs_tar[-1], shape=(int(batch_size/8), -1), name=\"reshape_lstm_tar\")\n",
    "\n",
    "norm_lstm1 = mx.sym.L2Normalization(data=out_lstm1, mode='instance', name=\"norm_lstm_src\") \n",
    "#norm_lstm2 = mx.sym.L2Normalization(data=out_lstm2, mode='instance', name=\"norm_lstm_tar\")\n",
    "#norm_product = norm_lstm1 * norm_lstm2\n",
    "\n",
    "#scalar_sum = mx.sym.sum_axis(data=norm_product, axis=1, name=\"sum_dot_product\")\n",
    "#scalar_output = mx.sym.Reshape(data=scalar_sum, shape=(int(batch_size/8), 1), name=\"reshape_scalar\")\n",
    "\n",
    "#shared_lstm_model = mx.sym.LogisticRegressionOutput(data=scalar_output, label=label, name=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_output = mx.sym.FullyConnected(data=out_lstm1, num_hidden=num_label, name=\"dense_net\")\n",
    "shared_lstm_model = mx.sym.SoftmaxOutput(data=dense_output, label=label, name=\"softmax_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_output = mx.sym.FullyConnected(data=out_lstm1, num_hidden=1, name=\"dense_net\")\n",
    "logistic_model = mx.sym.LogisticRegressionOutput(data=dense_output, label=label, name=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [mx.gpu(i) for i in range(8)]\n",
    "shared_model = mx.mod.Module(symbol=logistic_model, \\\n",
    "                                 data_names=['data'], \\\n",
    "                                 label_names=['label'], \\\n",
    "                                 context=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.logMultiprocessing)  # logging to stdout\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "str_handler = logging.FileHandler(sys.argv[1]+\"_logging_logregnet.txt\", \"w\")\n",
    "root_logger.addHandler(str_handler)\n",
    "root_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rate for stop or start classifier (here we're in the start classifier.)\n",
    "if sys.argv[1] == \"stop\":\n",
    "    learn_rate = 0.0004\n",
    "\n",
    "if sys.argv[1] == \"start\":\n",
    "    learn_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_rate = 0.0002\n",
    "opt_params = {\n",
    "    'learning_rate': learn_rate,\n",
    "    'wd': 0.00001\n",
    "}\n",
    "\n",
    "# Setup iterators for test data.\n",
    "test_train = mx.io.NDArrayIter(data=x_train, label=y_train, \\\n",
    "                               data_name='data', label_name='label', \\\n",
    "                               batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterator for evaluation.\n",
    "test_eval = mx.io.NDArrayIter(data=x_eval, label=y_eval, \\\n",
    "                               data_name='data', label_name='label', \\\n",
    "                               batch_size=batch_size, shuffle=False)\n",
    "\n",
    "max_accuracy = 0.0\n",
    "saved_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_point_analysis():\n",
    "    def _callback(iter_no, sym, arg, aux):\n",
    "        global max_accuracy\n",
    "        global saved_model\n",
    "\n",
    "        print(\"Check Point: \", iter_no)\n",
    "        output = shared_model.predict(test_eval).asnumpy()\n",
    "        y_prediction = np.round(output).ravel()\n",
    "        print(\"Evaluating Accuracy at Thr=0.50: \", output.shape, (1.0 * np.sum(np.equal(y_prediction, y_eval)) / len(y_eval)))\n",
    "\n",
    "        output = shared_model.predict(test_iter).asnumpy()\n",
    "        y_prediction = np.round(output).ravel()\n",
    "        accuracy = 1.0 * np.sum(np.equal(y_prediction, y_test)) / len(y_test)\n",
    "        print(\"Testing Accuracy at Thr=0.50: \", output.shape, (1.0 * np.sum(np.equal(y_prediction, y_test)) / len(y_test)))\n",
    "\n",
    "        output = shared_model.predict(test_train).asnumpy()\n",
    "        y_prediction = np.round(output).ravel()\n",
    "        print(\"Training Accuracy at Thr=0.50: \", output.shape, (1.0 * np.sum(np.equal(y_prediction, y_train)) / len(y_train)))\n",
    "    \n",
    "        if max_accuracy < accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            saved_model = shared_model\n",
    "    return _callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = 1 #200\n",
    "for i in range(check_point):\n",
    "    shared_model.fit(train_iter,  \t\t\t\t\t# train data\n",
    "                      eval_data=eval_iter,  \t\t\t\t# validation data\n",
    "                      optimizer='adam', \n",
    "                      optimizer_params=opt_params,  \n",
    "                      #initializer=mx.init.Xavier(factor_type=\"in\", magnitude=2.34),\n",
    "                      eval_metric=mx.metric.CompositeEvalMetric(metrics=[\"acc\"]), \n",
    "                      #batch_end_callback=mx.callback.Speedometer(max_data_size, 1), \n",
    "                      epoch_end_callback=check_point_analysis(),\n",
    "                      num_epoch=500)  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Model\n",
    "\n",
    "prefix=\"general_lstm_model_\"+sys.argv[1]\n",
    "saved_model.save_checkpoint(prefix=prefix, epoch=check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "netgraph = mx.viz.plot_network(logistic_model, title=sys.argv[1]+\"_lstm_architecture\",save_format='pdf')\n",
    "netgraph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "output = saved_model.predict(test_train).asnumpy()\n",
    "#y_prediction = np.round(output).ravel()\n",
    "#print(\"\\nTraining Accuracy at Thr=0.50: \", output.shape, (1.0 * np.sum(np.equal(y_prediction, y_train)) / len(y_train)))\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_true=y_train, y_score=output)\n",
    "\n",
    "score = []\n",
    "for i in range(len(thr)):\n",
    "    tp = tpr[i]\n",
    "    fn = 1 - tpr[i]\n",
    "    fp = fpr[i]\n",
    "    tn = 1 - fpr[i]\n",
    "    \n",
    "    maximize = tp + tn\n",
    "    \n",
    "    #print(tpr, fnr, fpr, tnr, maximize)\n",
    "    #print(maximize)\n",
    "    score.append(maximize)\n",
    "\n",
    "index = np.argmax(score)\n",
    "print(index, fpr[index], tpr[index], thr[index], score[index])\n",
    "\n",
    "result = [int(output[i] >= thr[index]) for i in range(len(output))]\n",
    "print(\"ROC adjusted Accuracy: \", (1.0 * np.sum(np.equal(result, y_train)) / len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr[index], tpr[index], 'ro')\n",
    "plt.xlabel('False +VE Rate')\n",
    "plt.ylabel('True +VE Rate')\n",
    "plt.savefig(sys.argv[1]+\"_general_lstm_roc.png\")\n",
    "\n",
    "# Test Accuracy\n",
    "\n",
    "output = saved_model.predict(test_iter).asnumpy()\n",
    "result = [int(output[i] >= thr[index]) for i in range(len(output))]\n",
    "print(\"Final Testing Accuracy: \", (1.0 * np.sum(np.equal(result, y_test)) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print \"Confusion Matrix: \"\n",
    "#print(metrics.confusion_matrix(y_true=y_train, y_pred=y_prediction))\n",
    "print(\"Classification Report: \")\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
